# DNS Spoofing Detection - Multi-Model Research Platform

Real-time AI-based DNS threat analysis system supporting **multiple detection models** with hybrid feature selection (SelectKBest + SHAP) on the BCCC-CIC-Bell-DNS-2024 dataset.

## ğŸ“‹ Project Overview

This comprehensive research platform implements **6 different detection approaches** for DNS spoofing and malicious DNS behavior:
- **Supervised Models**: LightGBM (gradient boosting), Random Forest (ensemble trees)
- **Unsupervised Models**: One-Class SVM (anomaly detection), Isolation Forest (outlier detection)
- **Deep Learning**: BiLSTM + K-Means (sequence analysis with clustering)
- **Ensemble**: Voting/stacking ensemble of multiple models

**Key Features:**
- Hybrid feature selection combining statistical filtering (SelectKBest) and model-based explainability (SHAP)
- Real-time inference with <100ms latency constraint
- Multi-class detection for various DNS attack types (malware, phishing, spam, data exfiltration)
- Modular architecture for easy model comparison and research

## ğŸ“Š Dataset

**BCCC-CIC-Bell-DNS-2024** (~4.3GB, 26 CSV files)
- Generated using ALFlowLyzer from CIC-Bell-DNS-2021 and CIC-Bell-DNS-EXF-2021
- **121 features** including network flow metrics, statistical features, and DNS-specific attributes
- **Two categories**:
   - `BCCC-CIC-Bell-DNS-EXF/`: Data exfiltration traffic (18 files: benign, light/heavy exfiltration)
   - `BCCC-CIC-Bell-DNS-Mal/`: Malicious DNS traffic (7 files: benign, malware, phishing, spam)

**Download**: [Kaggle Dataset](https://www.kaggle.com/datasets/bcccdatasets/malicious-dns-and-attacks-bccc-cic-bell-dns-2024)

**Citation:**
> Shafi, MohammadMoein, Arash Habibi Lashkari, Hardhik Mohanty. "Unveiling Malicious DNS Behavior Profiling and Generating Benchmark Dataset through Application Layer Traffic Analysis". *Computers and Electrical Engineering*, 2024.

## ğŸ—ï¸ Project Structure

```
project_root/
â”œâ”€â”€ BCCC-CIC-Bell-DNS-2024/          # Dataset directory (~4.3GB)
â”‚   â”œâ”€â”€ BCCC-CIC-Bell-DNS-EXF/       # Exfiltration traffic (18 CSV files)
â”‚   â””â”€â”€ BCCC-CIC-Bell-DNS-Mal/       # Malicious traffic (7 CSV files)
â”‚
â”œâ”€â”€ configs/                          # Configuration files
â”‚   â”œâ”€â”€ base_config.yaml             # Shared settings (data paths, preprocessing)
â”‚   â”œâ”€â”€ lightgbm_config.yaml         # LightGBM hyperparameters
â”‚   â”œâ”€â”€ random_forest_config.yaml    # Random Forest hyperparameters
â”‚   â”œâ”€â”€ ocsvm_config.yaml            # One-Class SVM hyperparameters
â”‚   â”œâ”€â”€ isolation_forest_config.yaml # Isolation Forest hyperparameters
â”‚   â”œâ”€â”€ bilstm_config.yaml           # BiLSTM + K-Means configuration
â”‚   â””â”€â”€ ensemble_config.yaml         # Ensemble model configuration
â”‚
â”œâ”€â”€ scripts/                          # Training scripts
â”‚   â”œâ”€â”€ train_lightgbm.py            # Train LightGBM (supervised)
â”‚   â”œâ”€â”€ train_random_forest.py       # Train Random Forest (supervised)
â”‚   â”œâ”€â”€ train_ocsvm.py               # Train One-Class SVM (unsupervised)
â”‚   â”œâ”€â”€ train_isolation_forest.py    # Train Isolation Forest (unsupervised)
â”‚   â”œâ”€â”€ train_bilstm_kmeans.py       # Train BiLSTM + K-Means (deep learning)
â”‚   â””â”€â”€ train_ensemble.py            # Train ensemble model
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/                      # Model implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py              # Models package
â”‚   â”‚   â”œâ”€â”€ base_model.py            # Abstract base classes (BaseDetector, etc.)
â”‚   â”‚   â”œâ”€â”€ lightgbm_model.py        # LightGBM detector
â”‚   â”‚   â”œâ”€â”€ random_forest.py         # Random Forest detector
â”‚   â”‚   â”œâ”€â”€ unsupervised_ocsvm.py    # One-Class SVM detector
â”‚   â”‚   â”œâ”€â”€ unsupervised_iforest.py  # Isolation Forest detector
â”‚   â”‚   â”œâ”€â”€ deep_bilstm_kmeans.py    # BiLSTM + K-Means detector
â”‚   â”‚   â””â”€â”€ ensemble_model.py        # Ensemble detector
â”‚   â”‚
â”‚   â”œâ”€â”€ trainers/                    # Training orchestration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_trainer.py          # Base trainer class
â”‚   â”‚   â”œâ”€â”€ supervised_trainer.py    # Supervised model trainer
â”‚   â”‚   â””â”€â”€ unsupervised_trainer.py  # Unsupervised model trainer
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                  # Evaluation and visualization
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py               # Metric computation utilities
â”‚   â”‚   â””â”€â”€ visualizations.py        # Plotting utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing.py             # Data loading & preprocessing
â”‚   â”œâ”€â”€ feature_selection.py         # Hybrid SelectKBest + SHAP
â”‚   â”œâ”€â”€ real_time_detection.py       # Real-time inference pipeline
â”‚   â””â”€â”€ utils.py                     # Helper functions
â”‚
â”œâ”€â”€ notebooks/                        # Jupyter notebooks
â”‚   â”œâ”€â”€ exploratory_analysis.ipynb   # Dataset EDA
â”‚   â”œâ”€â”€ model_comparison.ipynb       # Compare all models
â”‚   â””â”€â”€ feature_importance.ipynb     # Feature analysis
â”‚
â”œâ”€â”€ models/                          # Saved model artifacts
â”œâ”€â”€ results/                         # Evaluation results
â”‚   â”œâ”€â”€ plots/                       # Visualizations
â”‚   â”œâ”€â”€ metrics/                     # Performance metrics
â”‚   â””â”€â”€ experiments/                 # Experiment tracking
â”‚
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ unsupervised_approach.md     # Unsupervised methods guide
â”‚   â”œâ”€â”€ supervised_vs_unsupervised.md # Model comparison
â”‚   â””â”€â”€ architecture.md              # System architecture (NEW)
â”‚
â”œâ”€â”€ tests/                           # Unit tests
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â””â”€â”€ test_feature_selection.py
â”‚
â”œâ”€â”€ logs/                            # Training logs
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # This file
```

## ğŸ¤– Detection Models

### 1. **LightGBM** (Supervised) â­
- **Type**: Gradient Boosting Decision Trees
- **Training**: Labeled benign + malicious traffic
- **Expected Accuracy**: ~96-98%
- **Strengths**: Fast training, high accuracy, feature importance
- **Use Case**: Production deployment, known attack detection
- **Script**: `scripts/train_lightgbm.py`
- **Config**: `configs/lightgbm_config.yaml`

### 2. **Random Forest** (Supervised)
- **Type**: Ensemble of decision trees
- **Training**: Labeled benign + malicious traffic
- **Expected Accuracy**: ~94-96%
- **Strengths**: Robust to overfitting, interpretable
- **Use Case**: Baseline comparison, feature importance validation
- **Script**: `scripts/train_random_forest.py`
- **Config**: `configs/random_forest_config.yaml`

### 3. **One-Class SVM** (Unsupervised) ğŸ†•
- **Type**: Anomaly detection (one-class classification)
- **Training**: Benign traffic only (no attack labels needed)
- **Expected Accuracy**: ~85-92%
- **Strengths**: Zero-day attack detection, no labeling required
- **Use Case**: Novel threat detection, anomaly-based defense
- **Script**: `scripts/train_ocsvm.py`
- **Config**: `configs/ocsvm_config.yaml`

### 4. **Isolation Forest** (Unsupervised) ğŸ†•
- **Type**: Tree-based anomaly detection
- **Training**: Benign traffic only
- **Expected Accuracy**: ~87-93%
- **Strengths**: Fast, scalable, handles high-dimensional data
- **Use Case**: Large-scale anomaly detection, real-time systems
- **Script**: `scripts/train_isolation_forest.py`
- **Config**: `configs/isolation_forest_config.yaml`

### 5. **BiLSTM + K-Means** (Deep Learning) ğŸ†•
- **Type**: Sequence modeling with clustering
- **Training**: Sequences of DNS flows
- **Expected Performance**: Depends on sequence design
- **Strengths**: Temporal pattern detection, complex behaviors
- **Use Case**: Advanced persistent threats, behavioral analysis
- **Script**: `scripts/train_bilstm_kmeans.py`
- **Config**: `configs/bilstm_config.yaml`

### 6. **Ensemble Model** (Meta-Learner) ğŸ†•
- **Type**: Voting/stacking ensemble
- **Training**: Combines multiple base models
- **Expected Accuracy**: Best overall (98%+)
- **Strengths**: Leverages strengths of all models
- **Use Case**: Critical deployments requiring highest accuracy
- **Script**: `scripts/train_ensemble.py`
- **Config**: `configs/ensemble_config.yaml`

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- 8GB+ RAM recommended (dataset is ~4.3GB)
- GPU optional (for BiLSTM model)
- Windows/Linux/MacOS

### Installation

1. **Navigate to project directory:**
   ```bash
   cd "c:\Users\Ishank\Desktop\cns project 2024 dataset"
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Verify dataset location:**
   ```bash
   dir BCCC-CIC-Bell-DNS-2024  # Windows
   ls BCCC-CIC-Bell-DNS-2024   # Linux/Mac
   ```

### Quick Start - Training Models

#### 1. LightGBM (Supervised - Recommended)

```bash
# Quick test with 10% sample
python scripts/train_lightgbm.py --sample 0.1 --experiment-name lightgbm_test

# Full training
python scripts/train_lightgbm.py --experiment-name lightgbm_full

# Custom hyperparameters
python scripts/train_lightgbm.py --config configs/lightgbm_config.yaml
```

#### 2. One-Class SVM (Unsupervised)

```bash
# Quick test
python scripts/train_ocsvm.py --sample 0.1 --experiment-name ocsvm_test

# Full training
python scripts/train_ocsvm.py --experiment-name ocsvm_full

# Adjust sensitivity (nu parameter)
python scripts/train_ocsvm.py --nu 0.01 --experiment-name ocsvm_strict
```

#### 3. Random Forest (Supervised)

```bash
# Quick test
python scripts/train_random_forest.py --sample 0.1 --experiment-name rf_test

# Full training
python scripts/train_random_forest.py --experiment-name rf_full
```

#### 4. Isolation Forest (Unsupervised)

```bash
# Quick test
python scripts/train_isolation_forest.py --sample 0.1 --experiment-name iforest_test

# Full training
python scripts/train_isolation_forest.py --experiment-name iforest_full
```

#### 5. Ensemble Model

```bash
# Train ensemble (trains base models automatically)
python scripts/train_ensemble.py --experiment-name ensemble_full

# Use pre-trained models
python scripts/train_ensemble.py --use-pretrained --experiment-name ensemble_pretrained
```

### Model Comparison

```bash
# Compare all models on same test set
python scripts/compare_models.py \
    --models lightgbm random_forest ocsvm iforest \
    --sample 0.1 \
    --output results/comparison_report.html
```

## ğŸ”§ Configuration System

The project uses a hierarchical configuration system:

### Base Configuration (`configs/base_config.yaml`)

Shared settings across all models:
```yaml
data:
  dataset_path: "BCCC-CIC-Bell-DNS-2024"
  test_size: 0.2
  random_state: 42
  
preprocessing:
  handle_missing: "median"
  scale_features: true
  
output:
  models_dir: "models"
  results_dir: "results"
```

### Model-Specific Configurations

Each model has its own config file that extends the base config:
- `lightgbm_config.yaml`: LightGBM hyperparameters
- `ocsvm_config.yaml`: One-Class SVM settings
- `random_forest_config.yaml`: Random Forest parameters
- etc.

**Edit configs** to customize training parameters!

## ğŸ“ˆ Training Pipeline

All models follow a consistent pipeline:

1. **Configuration Loading**: Load base + model-specific config
2. **Data Loading**: Memory-efficient CSV loading (pandas/Dask)
3. **Preprocessing**: Missing values, encoding, normalization
4. **Train/Test Split**: Stratified split (preserves class distribution)
5. **Feature Selection** (optional): SelectKBest + SHAP
6. **Model Training**: Train model with specified hyperparameters
7. **Evaluation**: Comprehensive metrics (accuracy, precision, recall, F1, ROC-AUC)
8. **Visualization**: Confusion matrix, ROC curves, feature importance
9. **Model Saving**: Persist model + metadata

## ğŸ¯ Expected Performance

| Model | Type | Accuracy | Training Time | Inference Speed | Use Case |
|-------|------|----------|---------------|-----------------|----------|
| LightGBM | Supervised | 96-98% | ~10 min | <50ms | Production |
| Random Forest | Supervised | 94-96% | ~15 min | <100ms | Baseline |
| One-Class SVM | Unsupervised | 85-92% | ~20 min | <100ms | Zero-day |
| Isolation Forest | Unsupervised | 87-93% | ~5 min | <30ms | Real-time |
| BiLSTM + K-Means | Deep Learning | TBD | ~60 min | <200ms | Research |
| Ensemble | Meta | 98%+ | ~30 min | <150ms | Critical |

*Times on 4.3GB dataset with i7 CPU, 16GB RAM*

## ğŸ” Real-Time Detection

Use any trained model for real-time detection:

```python
from src.models import load_model
from src.real_time_detection import RealTimeDNSDetector

# Load trained model
model = load_model('models/lightgbm_best.pkl')

# Initialize detector
detector = RealTimeDNSDetector(model=model)

# Predict single DNS flow
flow_data = {...}  # Dictionary with 121 DNS features
result = detector.predict_single(flow_data)

print(f"Prediction: {result['label']}")        # 'Benign' or 'Malicious'
print(f"Confidence: {result['confidence']:.2%}")  # 95.4%
print(f"Latency: {result['latency_ms']:.1f}ms")  # 23.4ms
```

## ğŸ“Š Model Architecture

### Abstract Base Classes

All models inherit from `BaseDetector`:

```python
from src.models import BaseDetector, SupervisedDetector, UnsupervisedDetector

class MyCustomDetector(SupervisedDetector):
    def build_model(self):
        # Build your model
        pass
    
    def train(self, X, y):
        # Training logic
        pass
    
    def predict(self, X):
        # Prediction logic
        pass
```

**Benefits:**
- Consistent API across all models
- Easy to add new models
- Built-in save/load functionality
- Standardized evaluation

## ğŸ“ Command Line Interface

### Common Arguments

All training scripts support:

```bash
--config CONFIG          # Path to config file
--sample FLOAT           # Sample fraction (0.0-1.0)
--experiment-name NAME   # Experiment identifier
--no-cache               # Disable caching
--clear-cache            # Clear cache before run
--verbose                # Detailed logging
```

### Model-Specific Arguments

**LightGBM:**
```bash
--skip-feature-selection  # Use all features
--k-best INT             # SelectKBest k value
--shap-top-n INT         # SHAP top features
```

**One-Class SVM:**
```bash
--nu FLOAT               # Outlier fraction (0.01-0.5)
--kernel STR             # 'rbf', 'poly', 'sigmoid'
--gamma STR              # 'scale', 'auto', or float
```

**Ensemble:**
```bash
--method STR             # 'voting', 'stacking', 'weighted'
--use-pretrained         # Load pre-trained base models
```

## ğŸ› Troubleshooting

### Memory Issues
- Use `--sample 0.1` for testing
- Enable Dask in `base_config.yaml`: `use_dask: true`
- Reduce feature count: lower `k_best` value

### Import Errors
```bash
# Verify all dependencies installed
pip install -r requirements.txt

# Check Python version
python --version  # Should be 3.8+
```

### Slow Training
- Start with small sample: `--sample 0.1`
- Reduce `n_estimators` in config
- Use cached data (don't use `--no-cache`)

### Model Comparison
- Ensure all models trained on same data split
- Use fixed `random_state` in `base_config.yaml`
- Compare metrics from same experiment run

## ğŸ“š Documentation

- **`docs/unsupervised_approach.md`**: Comprehensive guide to unsupervised methods
- **`docs/supervised_vs_unsupervised.md`**: Comparison of approaches
- **`docs/architecture.md`**: System design and architecture (TODO)
- **`.github/copilot-instructions.md`**: Development guidelines

## ğŸ§ª Testing

Run unit tests:

```bash
# All tests
pytest tests/

# Specific module
pytest tests/test_models.py

# With coverage
pytest --cov=src tests/
```

## ğŸ¤ Contributing

This is a research project for DNS spoofing detection. Contributions welcome!

**To add a new model:**
1. Create model class inheriting from `BaseDetector` or `SupervisedDetector`/`UnsupervisedDetector`
2. Implement required abstract methods: `build_model()`, `train()`, `predict()`, `evaluate()`
3. Create config file in `configs/`
4. Create training script in `scripts/`
5. Update `src/models/__init__.py`

## ğŸ“– Research Context

This project supports research in:
- **Malicious DNS behavior profiling**
- **Zero-day attack detection** (unsupervised methods)
- **Feature engineering** for DNS traffic
- **Model comparison** for cybersecurity
- **Real-time threat detection** systems

## âœ… Key Features

âœ… **6 detection models** (supervised, unsupervised, deep learning, ensemble)  
âœ… **Modular architecture** (easy to extend and compare)  
âœ… **Consistent API** (BaseDetector abstract class)  
âœ… **Hybrid feature selection** (SelectKBest + SHAP)  
âœ… **Memory-efficient** (handles 4.3GB dataset)  
âœ… **Real-time inference** (<100ms latency)  
âœ… **Comprehensive evaluation** (10+ metrics, visualizations)  
âœ… **Experiment tracking** (reproducible results)  
âœ… **Production-ready** (save/load, logging, error handling)

---

**Status**: âœ… Structure implemented | âš ï¸ Some models pending | ğŸš€ Ready for research

For questions or issues, consult the documentation in `docs/` or review configuration files in `configs/`.
